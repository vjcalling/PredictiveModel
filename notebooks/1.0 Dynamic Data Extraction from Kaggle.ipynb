{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Titanic Disaster Data From Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading https://files.pythonhosted.org/packages/24/3d/977140bd94bfb160f98a5c02fdfbb72325130f12a325cf993182956e9d0e/python_dotenv-0.9.1-py2.py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#We will directly load Kaggle credentials from .env file, hence we are importing python-dotenv.\n",
    "# More info: https://stackoverflow.com/questions/41546883/can-somebody-explain-the-use-of-python-dotenv-module\n",
    "\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find .env automatically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vjcalling\n"
     ]
    }
   ],
   "source": [
    "# extracting environment variable using os.environ.get\n",
    "import os\n",
    "KAGGLE_USERNAME = os.environ.get(\"KAGGLE_USERNAME\")\n",
    "print(KAGGLE_USERNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from requests import session\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from requests import session\n",
    "# payload\n",
    "payload = {\n",
    "    'action': 'login',\n",
    "    'username': os.environ.get(\"KAGGLE_USERNAME\"),\n",
    "    'password': os.environ.get(\"KAGGLE_PASSWORD\")\n",
    "}\n",
    "\n",
    "\n",
    "def extract_data(url, file_path):\n",
    "    '''\n",
    "    extract data from kaggle\n",
    "    '''\n",
    "    login_url = 'https://www.kaggle.com/account/login'\n",
    "    # setup session\n",
    "    with session() as c:\n",
    "        c.post('https://www.kaggle.com/account/login', data=payload)\n",
    "        # oppen file to write\n",
    "        with open(file_path, 'wb') as handle:\n",
    "            response = c.get(login_url).text\n",
    "            #need to add antiForgeryToken for us to download data from Kagglw\n",
    "            AFToken = response[response.index('antiForgeryToken') + 19:response.index('isAnonymous: ')-12]\n",
    "            payload['__RequestVerificationToken']=AFToken\n",
    "            c.post(login_url + \"?isModal=true&returnUrl=/\", data=payload)\n",
    "            response = c.get(url, stream=True)\n",
    "            for block in response.iter_content(1024):\n",
    "                handle.write(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls\n",
    "train_url = 'https://www.kaggle.com/c/titanic/download/train.csv'\n",
    "test_url = 'https://www.kaggle.com/c/titanic/download/test.csv'\n",
    "\n",
    "# file paths\n",
    "raw_data_path = os.path.join(os.path.pardir,'data','raw')\n",
    "train_data_path = os.path.join(raw_data_path, 'train.csv')\n",
    "test_data_path = os.path.join(raw_data_path, 'test.csv')\n",
    "\n",
    "# extract data\n",
    "extract_data(train_url,train_data_path)\n",
    "extract_data(test_url,test_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if files are created\n",
    "\n",
    "#Windows\n",
    "!dir ..\\\\data\\\\raw\n",
    "\n",
    "#Linux\n",
    "#!ls -l ../data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builiding the file script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_raw_data_script_file = os.path.join(os.path.pardir,'src','data','get_raw_data.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ..\\src\\data\\get_raw_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $get_raw_data_script_file\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from requests import session\n",
    "import logging\n",
    "\n",
    "\n",
    "# payload for login to kaggle\n",
    "payload = {\n",
    "    'action': 'login',\n",
    "    'username': os.environ.get(\"KAGGLE_USERNAME\"),\n",
    "    'password': os.environ.get(\"KAGGLE_PASSWORD\")\n",
    "}\n",
    "\n",
    "\n",
    "def extract_data(url, file_path):\n",
    "    '''\n",
    "    extract data from kaggle\n",
    "    '''\n",
    "    login_url = 'https://www.kaggle.com/account/login'\n",
    "    # setup session\n",
    "    with session() as c:\n",
    "        c.post('https://www.kaggle.com/account/login', data=payload)\n",
    "        # oppen file to write\n",
    "        with open(file_path, 'w') as handle:\n",
    "            response = c.get(login_url).text\n",
    "            #need to add antiForgeryToken for us to download data from Kagglw\n",
    "            AFToken = response[response.index('antiForgeryToken') + 19:response.index('isAnonymous: ')-12]\n",
    "            payload['__RequestVerificationToken']=AFToken\n",
    "            c.post(login_url + \"?isModal=true&returnUrl=/\", data=payload)\n",
    "            response = c.get(url, stream=True)\n",
    "            for block in response.iter_content(1024):\n",
    "                handle.write(str(block))\n",
    "\n",
    "\n",
    "                \n",
    "def main(project_dir):\n",
    "    '''\n",
    "    main method\n",
    "    '''\n",
    "    # get logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info('getting raw data')\n",
    "    \n",
    "    # urls\n",
    "    train_url = 'https://www.kaggle.com/c/titanic/download/train.csv'\n",
    "    test_url = 'https://www.kaggle.com/c/titanic/download/test.csv'\n",
    "\n",
    "    # file paths\n",
    "    raw_data_path = os.path.join(project_dir,'data','raw')\n",
    "    train_data_path = os.path.join(raw_data_path, 'train.csv')\n",
    "    test_data_path = os.path.join(raw_data_path, 'test.csv')\n",
    "\n",
    "    # extract data\n",
    "    extract_data(train_url,train_data_path)\n",
    "    extract_data(test_url,test_data_path)\n",
    "    logger.info('downloaded raw training and test data')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # getting root directory\n",
    "    project_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)\n",
    "    \n",
    "    # setup logger\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "\n",
    "    # find .env automatically by walking up directories until it's found\n",
    "    dotenv_path = find_dotenv()\n",
    "    # load up the entries as environment variables\n",
    "    load_dotenv(dotenv_path)\n",
    "\n",
    "    # call the main\n",
    "    main(project_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-30 18:08:18,267 - __main__ - INFO - getting raw data\n",
      "2018-08-30 18:08:32,118 - __main__ - INFO - downloaded raw training and test data\n"
     ]
    }
   ],
   "source": [
    "!python $get_raw_data_script_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
